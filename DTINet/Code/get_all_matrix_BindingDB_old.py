import os, sys, uuid
from tkinter import Label
import numpy as np
import pandas as pd
from tqdm import tqdm
import pubchempy as pcp
import multiprocessing as mp
import time
import json
from pubchempy import Compound
from rdkit import Chem
from rdkit import DataStructs
import multiprocessing as mp
import xml.etree.ElementTree as ET
from itertools import repeat
import requests
import logging
from re import search
import argparse
import argparse
from rdkit import RDLogger                     
import subprocess as sp
from shutil import rmtree
from sklearn.preprocessing import MinMaxScaler


def get_DB_name(path):
	"""
	This function returns the name of the DB.
	"""
	DB_NAMES = ['BIOSNAP', 'BindingDB', 'Davis_et_al', 'DrugBank', 'E', 'GPCR', 'IC', 'NR']
	for db in DB_NAMES:
		if search(db, path):
			logging.info(f'Database: {db}')
			if db in ['E', 'GPCR', 'IC', 'NR']:
				db = os.path.join('Yamanashi_et_al_GoldStandard', db)
				return db
			else:
				return db
	logging.error(f'Database: {db} not found')
	sys.exit('Please provide a valid database')

def check_and_create_folder(db_name):
	if not os.path.exists(os.path.join('../Data', db_name)):
		os.mkdir(os.path.join('../Data', db_name))
#

def pubchem_to_drugbankid():
    '''
    Parse  DrugBank DB xml and 
    create a dictionary from PubChemID to DrugBankID
    '''
    logging.debug('Reading DrugBank xml database')
    tree = ET.parse('../../DB/Data/cross_side_information_DB/DrugBank/Data/full_database.xml')
    logging.debug('Succesfully read!')
    root = tree.getroot()
    dbids = []
    pubchemids = []
    for drug_entry in tqdm(root):
        drugbank_ID = drug_entry.find('{http://www.drugbank.ca}drugbank-id').text
        pubchem_id = np.nan # to not repeat id if it does not appear later
        for props in drug_entry.findall('.//{http://www.drugbank.ca}external-identifier'):
            for prop in props:
                if(prop.text == 'PubChem Compound'): 
                    pubchem_id = props[1].text
                break # romper una vez que encuentre el pubchem 
        dbids.append(drugbank_ID)
        pubchemids.append(pubchem_id)
    #
    dic_cid_dbid = dict((zip(pubchemids, dbids)))
    # first element is nan, delete
    dic_cid_dbid[list(dic_cid_dbid.keys())[0]]
    dic_cid_dbid.pop(list(dic_cid_dbid.keys())[0])
    return dic_cid_dbid


def get_protein_nodes_BindingDB():
	pass

def main():
	'''
	ff
	'''
	parser = argparse.ArgumentParser() 
	parser.add_argument("-v", "--verbose", dest="verbosity", action="count", default=3,
					help="Verbosity (between 1-4 occurrences with more leading to more "
						"verbose logging). CRITICAL=0, ERROR=1, WARN=2, INFO=3, "
						"DEBUG=4")
	parser.add_argument('-json', help="If selected, outputs a dictionary in json", action="store_true")
	parser.add_argument("dbPath", help="Path to the database output ('BIOSNAP', 'BindingDB', 'Davis_et_al', 'DrugBank_FDA', 'E', 'GPCR', 'IC', 'NR')", type=str)

	args = parser.parse_args()
	RDLogger.DisableLog('rdApp.*')   # disablen warnigns in rdkit
	# -) log info; 
	# define logging level
	log_levels = {
		0: logging.CRITICAL,
		1: logging.ERROR,
		2: logging.WARN,
		3: logging.INFO,
		4: logging.DEBUG,
	}
	# set the logging info
	level= log_levels[args.verbosity]
	fmt = '[%(levelname)s] %(message)s'
	logging.basicConfig(format=fmt, level=level)
	logging.info(
		'''
		This script needs:
			- common coordinate .tsv files (generated by get_coord.py)
			- DTI for each model (as tsv coordinate file)
		
		Returns:
			- mat*.txt
			- Similarity_Matrix_Drugs.txt
			- Similarity_Matrix_Proteins.txt
		'''
		)
	# OUTPUT DIRECTORY
	# sanity check
	DB_PATH = args.dbPath
	logging.info(f'Working in output folder for: {DB_PATH}')
	db_name = get_DB_name(DB_PATH)
	check_and_create_folder(db_name)
	# Create relative output path
	wdir = os.path.join('../Data', db_name)
	# wdir = '../Data/BindingDB'

	## LOAD BindingDB
	DBCOLS = ['PubChemID', 'UniprotID', 'SMILES', 'SEQ', 'Label']
	bindingdb = pd.read_csv(os.path.join(wdir, 'BindingDB.txt'), sep=" ", header=None, names=DBCOLS )
	bindingdb.loc[:, 'PubChemID'] = bindingdb.loc[:, 'PubChemID'].astype(int) # not float

	# PROTEIN NODES (de momento deber√≠a ser lo mismo que en las otras ya que no se tienen en cuenta los DTIs)
	#file_path_prot = os.path.join(wdir, 'protein.txt')
	#file_path_seqs = os.path.join(wdir, 'protein_seqs.fasta')
	#list_of_protein_nodes, list_of_protein_seqs = get_protein_nodes(file_path_prot, file_path_seqs, PPI, prot_dis, DTI)

	## DTIs
	dic_cid_dbid = pubchem_to_drugbankid()
	# df_drug_se['Pubchem_map_flat'] = df_drug_se['Pubchem_flat'].map(dic_cid_dbid)
	bindingdb.loc[:, 'PubChemID'] = bindingdb.loc[:, 'PubChemID'].astype(str) # not float
	bindingdb['DrugBankID'] = bindingdb['PubChemID'].map(dic_cid_dbid)
	dtis = bindingdb[['DrugBankID', 'UniprotID']][bindingdb.Label == 1]
	dtis = dtis.dropna()
	#dtis = dtis.dropna() # 1513dro
	#dtis[dtis.Label == 1]